{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 1 - Part 2: Lambda Calculus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lab is an exploration and learning exercise to be done in a group and also in discussion with the teachers and other students.\n",
    "\n",
    "Before starting, please read the following instructions on [how to work on group assignments](https://github.com/sdobnik/computational-semantics/blob/master/README.md).\n",
    "\n",
    "Write all your answers and the code in the appropriate boxes below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This task needs NLTK and Jupyter Notebook (IPython package).\n",
    "import nltk\n",
    "from nltk.grammar import FeatureGrammar\n",
    "from utils import display_latex, display_translation, display_tree, display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Types of (Expression) objects in Python/NLTK and semantic types\n",
    "\n",
    "First order logic expressions and lambda expressions are our **object language** that we use to represent semantics of linguistic expressions. The object language is implemented in Python which is the **meta language**. We write logic and lambda expressions as strings that are then converted to Python/NLTK objects that are then processed with Python methods.\n",
    "\n",
    "The goal of this question is to learn about **types**. In the object language we use types that correspond to the meaning of the corresponding expressions in natural language (the basic types `e` and `t` and function types based on these such as `<e,t>`), in the meta language we use types that are practically required for computation (`<IndividualVariableExpression x>`). How do these type systems compare?\n",
    "\n",
    "We can translate logic expressions written as a string into one of the `nltk.sem.logic.Expression` types as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_expr = nltk.sem.Expression.fromstring\n",
    "\n",
    "# different representations have different valid types:\n",
    "expressions = [\n",
    "    read_expr(r\"x\"),\n",
    "    read_expr(r\"P\"),\n",
    "    read_expr(r\"rob\"),\n",
    "    read_expr(r\"\\x.P(x)\"),\n",
    "    read_expr(r\"\\x.homosapien(x)\"),\n",
    "    read_expr(r\"P(x)\"),\n",
    "    read_expr(r\"P(rob)\"),\n",
    "    read_expr(r\"homosapien(rob)\"),\n",
    "    read_expr(r\"(\\y \\x.love(x, y))(rob)\"),\n",
    "    read_expr(r\"homosapien(rob) & run(rob)\"),\n",
    "    read_expr(r\"exists x.(homosapien(x) & run(x))\"),\n",
    "    read_expr(r\"all x.(homosapien(x) & run(x))\"),\n",
    "]\n",
    "\n",
    "for expr in expressions:\n",
    "    display_latex(expr, with_types=True)\n",
    "    \n",
    "    \n",
    "display(Markdown(r\"\"\"----\n",
    "\n",
    "**Note**: *Python interprets `\\` as a marker for special characters.\n",
    "To prevent this, we use `r` in `r\"strings\"` in order to force the raw interpretation of strings.*\n",
    "\n",
    "----\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the following type assumptions:\n",
    "```\n",
    "x : e\n",
    "P : <e, t>\n",
    "rob: e\n",
    "```\n",
    "**1a.** What is the semantic type of each expression below? Assume an approprate type for `homosapien` and `run` based on how they are used in other examples. **[5 marks]**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace `???` below:\n",
    "\n",
    "```\n",
    "P(x): t\n",
    "P(rob): t\n",
    "homosapien(rob): t\n",
    "homosapien: t\n",
    "\\x.P(x): <e,t>\n",
    "\\x.homosapien(x): <e,t>\n",
    "(\\y \\x.love(x, y))(rob): <e,t>\n",
    "homosapien(rob) & run(rob): t\n",
    "exists x.(homosapien(x) & run(x)): t\n",
    "all x.(homosapien(x) & run(x)): t\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1b. Some well-formed NLTK expressions do not have a valid semantic type. Explain the issue in the expression below **[2 marks]**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_latex(read_expr(r\"rob & marry\"), with_types=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to nltk type method this expression is type t but it has no truth value, because they are 2 entities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Translate verb phrases\n",
    "\n",
    "Translate the verb phrases using $\\lambda$ abstracts and verify the resulting formulae with `Expression.fromstring`. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translations = {\n",
    "    \"read by Rob\": read_expr(r\"\\x.read(rob, x)\"),\n",
    "    \"read a book\": read_expr(r\"\\x. exists y. (book(y) & read(x, y))\"),\n",
    "}\n",
    "\n",
    "for text, expr in translations.items():\n",
    "    display_translation(text, expr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace `xxx` with valid representations in the dictionary of expressions **[4 marks]**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the following translations:\n",
    "translations = {\n",
    "    \"be admired by no-one\":        read_expr(r\"\\x -exists y.admire(x, y)\"),\n",
    "    \"catch a fish and eat it\":     read_expr(r\"\\x. exists y.(fish(y) & catch(x,y) & eat(x,y))\"),\n",
    "    \"read a book or watch a film\": read_expr(r\"\\x. exists y.((book(y) & read(x,y)) | exists z.(film(z) & watch(x,z)))\"),\n",
    "    \"give every boy a dime\":       read_expr(r\"\\x. all y.(boy(y) -> exists z.(dime(z) & give(x,y,z)))\")\n",
    "}\n",
    "for text, expr in translations.items():\n",
    "    display_translation(text, expr)\n",
    "# existential goes with conjunction\n",
    "# universal goes with implication\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Function application and $\\beta$-reduction\n",
    "In the following examples some code has been deleted and replaced with `<????>`. What has been deleted? Verify that your answer is correct. **[4 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1 = read_expr(r'\\x.(like(x,rob))')\n",
    "e2 = read_expr(r'pip')\n",
    "e3 = nltk.sem.ApplicationExpression(e1,e2) \n",
    "\n",
    "display_latex(e3.simplify())\n",
    "# with reuslt like(pip,rob).\n",
    "display_latex(read_expr(r\"like(pip, rob)\"))\n",
    "\n",
    "e1 = read_expr(r'\\P.P(pip)')\n",
    "e2 = read_expr(r'\\x.play(x, scherzo)') \n",
    "e3 = nltk.sem.ApplicationExpression(e1,e2)\n",
    "display_latex(e3.simplify())\n",
    "# with result play(pip,scherzo).\n",
    "display_latex(read_expr(r\"play(pip,scherzo)\"))\n",
    "\n",
    "e1 = read_expr(r'\\P exists x. (woman(x) & P(x))')\n",
    "e2 = read_expr(r'\\x.play(x,etude)') \n",
    "e3 = nltk.sem.ApplicationExpression(e1,e2) \n",
    "display_latex(e3.simplify())\n",
    "# with result exists x.(woman(x) & play(x,etude)).\n",
    "display_latex(read_expr(r\"exists x.(woman(x) & play(x,etude))\"))\n",
    "\n",
    "e1 = read_expr(r'\\P.\\x. (P(like(x)))')\n",
    "e2 = read_expr(r'\\P.all x. (musician(x) -> P(x))') \n",
    "e3 = nltk.sem.ApplicationExpression(e1,e2) \n",
    "display_latex(e3.simplify())\n",
    "# with result \\x.all z2.(musician(z2) -> like(x,z2)).\n",
    "display_latex(read_expr(r\"\\x.all z2.(musician(z2) -> like(x,z2))\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Extending the FCFG grammar\n",
    "\n",
    "Extend the grammar simple_sem.fcfg that comes with NLTK `(~/nltk_data/grammars/book_grammars/)` so that it will cover the following sentences:\n",
    "\n",
    "- no man gives a bone to a dog **[4 marks]**\n",
    "- a boy and a girl chased every dog **[2 marks]**\n",
    "- every dog chased a boy and a girl **[2 marks]**\n",
    "- a brown cat chases a white dog **[4 marks]**\n",
    "\n",
    "The last example includes adjectives. Several different kinds of adjectives are discussed in the literature [(cf. Kennedy, 2012)](http://semantics.uchicago.edu/kennedy/docs/routledge.pdf). In this example we have an intersective adjective. The denotiation we want for \"brown cat\" is a a set that we get by intersecting the set of individuals that are brown and the set of individuals that are cats.\n",
    "\n",
    "C. Kennedy. Adjectives. In G. Russell, editor, The Routledge Companion to Philosophy of Language, chapter 3.3, pages 328â€“341. Routledge, 2012.\n",
    "\n",
    "The original grammar is included in the code below as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcfg_string_orginal = r\"\"\"\n",
    "% start S\n",
    "############################\n",
    "# Grammar Rules\n",
    "#############################\n",
    "\n",
    "S[SEM = <?subj(?vp)>] -> NP[NUM=?n,SEM=?subj] VP[NUM=?n,SEM=?vp]\n",
    "\n",
    "NP[NUM=?n,SEM=<?det(?nom)> ] -> Det[NUM=?n,SEM=?det]  Nom[NUM=?n,SEM=?nom]\n",
    "NP[LOC=?l,NUM=?n,SEM=?np] -> PropN[LOC=?l,NUM=?n,SEM=?np]\n",
    "\n",
    "Nom[NUM=?n,SEM=?nom] -> N[NUM=?n,SEM=?nom]\n",
    "\n",
    "VP[NUM=?n,SEM=?v] -> IV[NUM=?n,SEM=?v]\n",
    "VP[NUM=?n,SEM=<?v(?obj)>] -> TV[NUM=?n,SEM=?v] NP[SEM=?obj]\n",
    "VP[NUM=?n,SEM=<?v(?obj,?pp)>] -> DTV[NUM=?n,SEM=?v] NP[SEM=?obj] PP[+TO,SEM=?pp]\n",
    "\n",
    "PP[+TO, SEM=?np] -> P[+TO] NP[SEM=?np]\n",
    "\n",
    "#############################\n",
    "# Lexical Rules\n",
    "#############################\n",
    "\n",
    "PropN[-LOC,NUM=sg,SEM=<\\P.P(angus)>] -> 'Angus'\n",
    "PropN[-LOC,NUM=sg,SEM=<\\P.P(cyril)>] -> 'Cyril'\n",
    "PropN[-LOC,NUM=sg,SEM=<\\P.P(irene)>] -> 'Irene'\n",
    " \n",
    "Det[NUM=sg,SEM=<\\P Q.all x.(P(x) -> Q(x))>] -> 'every'\n",
    "Det[NUM=pl,SEM=<\\P Q.all x.(P(x) -> Q(x))>] -> 'all'\n",
    "Det[SEM=<\\P Q.exists x.(P(x) & Q(x))>] -> 'some'\n",
    "Det[NUM=sg,SEM=<\\P Q.exists x.(P(x) & Q(x))>] -> 'a'\n",
    "Det[NUM=sg,SEM=<\\P Q.exists x.(P(x) & Q(x))>] -> 'an'\n",
    "\n",
    "N[NUM=sg,SEM=<\\x.man(x)>] -> 'man'\n",
    "N[NUM=sg,SEM=<\\x.girl(x)>] -> 'girl'\n",
    "N[NUM=sg,SEM=<\\x.boy(x)>] -> 'boy'\n",
    "N[NUM=sg,SEM=<\\x.bone(x)>] -> 'bone'\n",
    "N[NUM=sg,SEM=<\\x.ankle(x)>] -> 'ankle'\n",
    "N[NUM=sg,SEM=<\\x.dog(x)>] -> 'dog'\n",
    "N[NUM=pl,SEM=<\\x.dog(x)>] -> 'dogs'\n",
    "\n",
    "IV[NUM=sg,SEM=<\\x.bark(x)>,TNS=pres] -> 'barks'\n",
    "IV[NUM=pl,SEM=<\\x.bark(x)>,TNS=pres] -> 'bark'\n",
    "IV[NUM=sg,SEM=<\\x.walk(x)>,TNS=pres] -> 'walks'\n",
    "IV[NUM=pl,SEM=<\\x.walk(x)>,TNS=pres] -> 'walk'\n",
    "TV[NUM=sg,SEM=<\\X x.X(\\ y.chase(x,y))>,TNS=pres] -> 'chases'\n",
    "TV[NUM=pl,SEM=<\\X x.X(\\ y.chase(x,y))>,TNS=pres] -> 'chase'\n",
    "TV[NUM=sg,SEM=<\\X x.X(\\ y.see(x,y))>,TNS=pres] -> 'sees'\n",
    "TV[NUM=pl,SEM=<\\X x.X(\\ y.see(x,y))>,TNS=pres] -> 'see'\n",
    "TV[NUM=sg,SEM=<\\X x.X(\\ y.bite(x,y))>,TNS=pres] -> 'bites'\n",
    "TV[NUM=pl,SEM=<\\X x.X(\\ y.bite(x,y))>,TNS=pres] -> 'bite'\n",
    "DTV[NUM=sg,SEM=<\\Y X x.X(\\z.Y(\\y.give(x,y,z)))>,TNS=pres] -> 'gives'\n",
    "DTV[NUM=pl,SEM=<\\Y X x.X(\\z.Y(\\y.give(x,y,z)))>,TNS=pres] -> 'give'\n",
    "\n",
    "P[+to] -> 'to'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your extension of this grammar here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcfg_string = fcfg_string_orginal + r\"\"\"\n",
    "## Your answers here\n",
    "\n",
    "NP[NUM=?n,SEM=<?det(?nom)>] -> Det[NUM=?n,SEM=?det] Nom[NUM=?n,SEM=?nom] CONJ Det[NUM=?n,SEM=?det] Nom[NUM=?n,SEM=?nom]\n",
    "NP[NUM=?n,SEM=<?det(?nom)>] -> Det[NUM=?n,SEM=?det] ADJ[SEM=?adj] Nom[NUM=?n,SEM=?nom] \n",
    "\n",
    "N[NUM=sg,SEM=<\\x.cat(x)>] -> 'cat'\n",
    "N[NUM=pl,SEM=<\\x.cat(x)>] -> 'cats'\n",
    "\n",
    "CONJ -> 'and'\n",
    "Det[NUM=pl,SEM=<\\P Q.all x.(P(x) -> Q(x))>] -> 'no'\n",
    "\n",
    "TV[NUM=sg,SEM=<\\X x.X(\\ y.chase(x,y))>,TNS=past] -> 'chased'\n",
    "TV[NUM=pl,SEM=<\\X x.X(\\ y.chase(x,y))>,TNS=past] -> 'chased'\n",
    "\n",
    "ADJ[SEM=<\\x.brown(x)>] -> 'brown'\n",
    "ADJ[SEM=<\\x.white(x)>] -> 'white'\n",
    "\n",
    "\"\"\"\n",
    "# Load `fcfg_string` as a feature grammar:\n",
    "syntax = FeatureGrammar.fromstring(fcfg_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code below without errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove sentences if you couldn't find answer for them\n",
    "sentences = [\n",
    "    'no man gives a bone to a dog',\n",
    "    'a boy and a girl chased every dog',\n",
    "    'every dog chased a boy and a girl',\n",
    "    'a brown cat chases a white dog',\n",
    "]\n",
    "for results in nltk.interpret_sents(sentences, syntax):\n",
    "    for (synrep, semrep) in results:\n",
    "        display(Markdown('----'))\n",
    "        display_latex(semrep) # prints the SEM feature of a tree\n",
    "        display_tree(synrep) # show the parse tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are working with iPython which is also running behind Jupyter notebooks and you are changing grammars and want to rerun a new version without restarting you may find `nltk.data.clear_cache()` useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marks\n",
    "\n",
    "This part of the assignment has a total of 27 marks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
